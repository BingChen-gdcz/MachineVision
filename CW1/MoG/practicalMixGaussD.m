function r=practicalMixGaussD

%EXTRA THINGS TO DO (Optional)

%1. Use the mixtures of Gaussians model to classify the skin/non-skin data
%2. Use the Gaussian model (with diagonal covariance) to classify
%face/non-face data (in FaceData.mat)
%3. Use the mixtures of Gaussians model (with diagonal covariance) to
%classify the face/non-face data
%4. Use the t-distribution instead of the normal distribution

im = imread('bob_small.jpeg');
load('bob_GroundTruth_small.mat','gt');

close all;
figure; set(gcf,'Color',[1 1 1]);
subplot(1,3,1); imagesc(im); axis off; axis image;
subplot(1,3,2); imagesc(gt); colormap(gray); axis off; axis image;
drawnow;

%load in training data - contains two variables each of size 3 x 10000
%Each column contains RGB values from one pixel in training data
load('RGBSkinNonSkin','RGBSkin','RGBNonSkin');

%fit Gaussian model for skin data
%TO DO - fill in this routine (it's below, at the bottom of this file)

[meanSkin covSkin] = fitGaussianModel(RGBSkin);

%fit Gaussian model for non-skin data
%TO DO - fill in this routine (below)
[meanNonSkin covNonSkin] = fitGaussianModel(RGBNonSkin);

%let's define priors for whether the pixel is skin or non skin
priorSkin = 0.3;
priorNonSkin = 0.7;

%now run through the pixels in the image and classify them as being skin or
%non skin - we will fill in the posterior
[imY imX imZ] = size(im);

posteriorSkin = zeros(imY,imX);
for (cY = 1:imY); 
    fprintf('Processing Row %d\n',cY);     
    for (cX = 1:imX);          
        %extract this pixel data
        thisPixelData = squeeze(double(im(cY,cX,:)));
        %calculate likelihood of this data given skin model
        %TO DO - fill in this routine (below)
        likeSkin = calcGaussianProb(thisPixelData,meanSkin,covSkin);
        %calculate likelihood of this data given non skin model
        likeNonSkin = calcGaussianProb(thisPixelData,meanNonSkin,covNonSkin);
        %TO DO (c):  calculate posterior probability from likelihoods and 
        %priors using BAYES rule. Replace this: 
        posteriorSkin(cY,cX) = likeSkin*priorSkin/(likeSkin*priorSkin+likeNonSkin*priorNonSkin);
        
    end;
end;

%draw skin posterior
clims = [0, 1];
subplot(1,3,3); imagesc(posteriorSkin, clims); colormap(gray); axis off; axis image;
% set(gca, 'clim', [0, 1]);




%==========================================================================
%==========================================================================

%the goal of this routine is to evaluate a Gaussian likleihood
function like = calcGaussianProb(data,gaussMean,gaussCov)

%TO DO (b) - fill in this routine
[nDim nData] = size(gaussMean);
%replace this
like = 1/((2*pi)^(nDim/2)*sqrt(det(gaussCov)))*exp(-0.5*(data-gaussMean).'*inv(gaussCov)*(data-gaussMean));


%==========================================================================
%==========================================================================

%the goal of this routine is to return the mean and covariance of a set of
%multidimensaional data.  It is assumed that each column of the 2D array
%data contains a single data point.  The mean vector should be a 3x1 vector
%with the mean RGB value.  The covariance should be a 3x3 covariance
%matrix. See the note at the top, which explains that using mean() is ok,
%but please compute the covariance yourself.
function [meanData covData] = fitGaussianModel(data);

[nDim nData] = size(data);

%TO DO (a): replace this
meanData = mean(data,2);
covData=zeros(3,3);

%covData=(data-meanData)*(data-meanData)'/nData
for i=1:nDim
    for j=1:nDim
        covData(i,j)=sum((data(i,:)-meanData(i)).*(data(j,:)-meanData(j)))/nData;
    
    end
end

%calculate mean of data.  You can do this using the MATLAB command 'mean'

%calculate covariance of data.  You should do this yourself to ensure you
%understand how.  Check you have the right answer by comparing with the
%matlab command 'cov'.

mixGaussTrue.k = 2;
mixGaussTrue.d = 1;


function mixGaussEst = fitMixGauss1d(data,k);
        
nData = size(data,2);

%MAIN E-M ROUTINE 
%there are nData data points, and there is a hidden variable associated
%with each.  If the hidden variable is 0 this indicates that the data was
%generated by the first Gaussian.  If the hidden variable is 1 then this
%indicates that the hidden variable was generated by the second Gaussian
%etc.

responsibilities =zeros(k, nData);

%in the E-M algorithm, we calculate a complete posterior distribution over
%the (nData) hidden variables in the E-Step.  In the M-Step, we
%update the parameters of the Gaussians (mean, cov, w).  

%we will initialize the values to random values
mixGaussEst.d = 1;
mixGaussEst.k = k;
mixGaussEst.weight = (1/k)*ones(1,k);
mixGaussEst.mean = 2*randn(1,k);
mixGaussEst.cov = 0.1+1.5*rand(1,1,k);

%calculate current likelihood
%TO DO - fill in this routine
logLike = getMixGaussLogLike(data,mixGaussEst);
fprintf('Log Likelihood Iter 0 : %4.3f\n',logLike);

%original no. of iteration is 20 
nIter = 30;
for (cIter = 1:nIter)
  pause(1)
   % ===================== =====================
   %Expectation step
   % ===================== =====================
   for (cData = 1:nData)
        %TO DO: fill in column of 'hidden' - caculate posterior probability that
        %this data point came from each of the Gaussians
        %replace this:
        hsum=0;
      
        for (i=1:mixGaussEst.k)
            hsum=hsum+mixGaussEst.weight(i)*getGaussProb(data(cData),mixGaussEst.mean(i),mixGaussEst.cov(i));
        end;
        for (i=1:mixGaussEst.k)
            
            responsibilities(i,cData) = mixGaussEst.weight(i)*getGaussProb(data(cData),mixGaussEst.mean(i),mixGaussEst.cov(i))/hsum;
        end;
   
    end;
   
   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood After E-Step Iter %d : %4.3f\n',cIter,logLike);

   %calculate the bound
   %TO DO - Fill in this routine
   bound = getMixGaussBound(data,mixGaussEst,responsibilities);
   fprintf('Bound After E-Step Iter %d : %4.3f\n',cIter,bound);
   

   % ===================== =====================
   %Maximization Step
   % ===================== =====================
   %for each constituent Gaussian
   for (cGauss = 1:k) 
        %TO DO:  Update weighting parameters mixGauss.weight based on the total
        %posterior probability associated with each Gaussian. Replace this:
        
        %sum1=0;
        %sum2=0;
        %for (cData = 1:nData)
        %    sum1=sum1+responsibilities(cGauss,cData); 
         %   for (cGauss = 1:k) 
          %      sum2=sum2+responsibilities(cGauss,cData);
           % end;
        %end;         
        mixGaussEst.weight(cGauss) = sum(responsibilities(cGauss,:),2)/sum(responsibilities(:)); 
   
        %TO DO:  Update mean parameters mixGauss.mean by weighted average
        %where weights are given by posterior probability associated with
        %Gaussian.  Replace this:
        
        %sum1=0;
        %sum2=0;
        %for (cData = 1:nData)            
        %    sum1=sum1+responsibilities(cGauss,cData)*data(cData);
        %    sum2=sum2+responsibilities(cGauss,cData);

        %end;  
        mixGaussEst.mean(cGauss) = (responsibilities(cGauss,:)*data')/sum(responsibilities(cGauss,:));
        %mixGaussEst.mean(cGauss) = sum((responsibilities(cGauss,:).*data),2)/sum(responsibilities(cGauss,:));
        %TO DO:  Update covarance parameter based on weighted average of
        %square distance from update mean, where weights are given by
        %posterior probability associated with Gaussian
        
        %sum1=0;
        %sum2=0;
        %for (cData = 1:nData)            
        %    sum1=sum1+responsibilities(cGauss,cData)*(data(cData)-mixGaussEst.mean(cGauss))^2 ;
        %    sum2=sum2+responsibilities(cGauss,cData);

        %end;  
        mixGaussEst.cov(1,1,cGauss) = sum(responsibilities(cGauss,:).*...
            (data-mixGaussEst.mean(cGauss))*(data-mixGaussEst.mean(cGauss))',2)...
            /sum(responsibilities(cGauss,:));
   end;
   
   %draw the new solution
   drawEMData1d(data,mixGaussEst);drawnow;

   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood After M-Step Iter %d : %4.3f\n',cIter,logLike);

   %calculate the bound
   bound = getMixGaussBound(data,mixGaussEst,responsibilities);
   fprintf('Bound After M-Step Iter %d : %4.3f\n',cIter,bound);   
end;

